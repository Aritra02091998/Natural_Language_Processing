{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3cd5285",
   "metadata": {},
   "source": [
    "### Bi-Directional RNN for News Classification\n",
    "\n",
    "Here we use Bi-Directional RNN to classify given news dataset into 4 classes:\n",
    "\n",
    "○ World (0)\n",
    "○ Sports (1)\n",
    "○ Business (2)\n",
    "○ Sci/Tech (3)\n",
    "\n",
    "We cleaned the dataset first:\n",
    "\n",
    "-> Converted the whole dataset to lower case.\n",
    "\n",
    "-> Removed stop words.\n",
    "\n",
    "-> Removed punctuation marks.\n",
    "\n",
    "-> Replaced numbers and words containing numbers as a sunstring with \"NUM\" tokens.\n",
    "\n",
    "We have used nn.Embedding layer here not to learn the embeddings, instead we have used word2vec word embeddings for the LSTM. Later we have initialized the nn.Embedding Layer with the word2vec learnt word embeddings.\n",
    "\n",
    "To learn the best possible embedding for the words in the dataset, we have trained the word2vec model for 50 epochs.\n",
    "\n",
    "We initialized word2vec model by the news sentences given in the dataset, and performed tokenization later using nltk to build the vocabulary.\n",
    "\n",
    "We trained the RNN model for 20 epochs to learn the pattern to the best using AdamW optimizer using a LR of 0.0001 \n",
    "\n",
    "The vanilla RNN Variant scores 82.8 % approx on Test Set while the Bi-Directional-RNN Variant scores 83.39 % approx on Test Set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b4c92ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b27d4a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbd8a12",
   "metadata": {},
   "source": [
    "### Load the train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3d58142",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = pd.read_csv('./NLP3/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64156dda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Zimbabwe annual inflation drops to 209 percent...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>More than 1,000 dead in Haiti (09/23/04)-- A m...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Seven die in Japan  #39;suicide pact #39; Japa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Security No. 1 for Afghan head President Hamid...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Palestinians say they hope Bush accepts dealin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>France Seeks Return of Reporters in Iraq Amid ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Ads Make Closing Arguments in Campaign (AP) AP...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Mourning for submariner spans an ocean HALIFAX...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>Palestinian Girl Killed in Gaza Strip, Medics ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>US Marine killed in Iraq #39;s western Anbar p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                               text  label\n",
       "0      0  Zimbabwe annual inflation drops to 209 percent...      0\n",
       "1      1  More than 1,000 dead in Haiti (09/23/04)-- A m...      0\n",
       "2      2  Seven die in Japan  #39;suicide pact #39; Japa...      0\n",
       "3      3  Security No. 1 for Afghan head President Hamid...      0\n",
       "4      4  Palestinians say they hope Bush accepts dealin...      0\n",
       "5      5  France Seeks Return of Reporters in Iraq Amid ...      0\n",
       "6      6  Ads Make Closing Arguments in Campaign (AP) AP...      0\n",
       "7      7  Mourning for submariner spans an ocean HALIFAX...      0\n",
       "8      8  Palestinian Girl Killed in Gaza Strip, Medics ...      0\n",
       "9      9  US Marine killed in Iraq #39;s western Anbar p...      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b69c5f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set contains total 2000 rows with [0 1 2 3] unique classes(labels)\n"
     ]
    }
   ],
   "source": [
    "print(f'Train set contains total {len(train_set)} rows with {train_set.label.unique()} unique classes(labels)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff3afc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_raw = train_set['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b95cef1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a603ae06",
   "metadata": {},
   "source": [
    "### Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98f67971",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_symbols(text):\n",
    "    pattern = r'[^\\w\\s]'  \n",
    "    cleaned_text = re.sub(pattern, '', text)\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fda6a3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    \n",
    "    stopwords_set = set(stopwords.words('english'))\n",
    "    text = text.split()\n",
    "    stopwords_removed_text = [word for word in text if word.lower() not in stopwords_set]\n",
    "    \n",
    "    return ' '.join(stopwords_removed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ddabb169",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set['text'] = train_set['text'].apply(lambda x: x.lower()) \n",
    "train_set['text'] = train_set['text'].apply(remove_symbols) \n",
    "train_set['text'] = train_set['text'].apply(remove_stopwords) \n",
    "train_set['text'] = train_set['text'].apply(lambda x: x.replace('\\\\', ' ')) \n",
    "train_set['text'] = train_set['text'].replace(r'\\b[a-zA-Z]*\\d+[a-zA-Z]*\\b', 'NUM', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90282f2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>zimbabwe annual inflation drops NUM percent re...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NUM dead haiti NUM mass grave haiti holds NUM ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>seven die japan NUM pact NUM japanese police f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>security NUM afghan head president hamid karza...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>palestinians say hope bush accepts dealing ara...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                               text  label\n",
       "0      0  zimbabwe annual inflation drops NUM percent re...      0\n",
       "1      1  NUM dead haiti NUM mass grave haiti holds NUM ...      0\n",
       "2      2  seven die japan NUM pact NUM japanese police f...      0\n",
       "3      3  security NUM afghan head president hamid karza...      0\n",
       "4      4  palestinians say hope bush accepts dealing ara...      0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc446967",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2ce4d25b",
   "metadata": {},
   "source": [
    "### Load the Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8bbddf03",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = pd.read_csv('./NLP3/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38f0c74b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set contains total 500 rows with [0 1 2 3] unique classes(labels)\n"
     ]
    }
   ],
   "source": [
    "print(f'Test set contains total {len(test_set)} rows with {test_set.label.unique()} unique classes(labels)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c2442314",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_raw = test_set['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f80ca42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "40980d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set['text'] = test_set['text'].apply(lambda x: x.lower()) \n",
    "test_set['text'] = test_set['text'].apply(remove_symbols) \n",
    "test_set['text'] = test_set['text'].apply(remove_stopwords) \n",
    "test_set['text'] = test_set['text'].apply(lambda x: x.replace('\\\\', ' ')) \n",
    "test_set['text'] = test_set['text'].replace(r'\\b[a-zA-Z]*\\d+[a-zA-Z]*\\b', 'NUM', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3618fcb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>detainees seen minimal threat washington alleg...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>japans army works plan cope north korean terro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>un council arrives nairobi un security council...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>apec ministers urge new effort trade talks pac...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>least five dead russia mine blast reuters reut...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                               text  label\n",
       "0      0  detainees seen minimal threat washington alleg...      0\n",
       "1      1  japans army works plan cope north korean terro...      0\n",
       "2      2  un council arrives nairobi un security council...      0\n",
       "3      3  apec ministers urge new effort trade talks pac...      0\n",
       "4      4  least five dead russia mine blast reuters reut...      0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872eb178",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a965e09a",
   "metadata": {},
   "source": [
    "### Vocabulary Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e12d37f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_sentence(sentence):\n",
    "    return word_tokenize(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aa48fc29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2500"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = train_set['text'].tolist() + test_set['text'].tolist()\n",
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ef384d46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2500"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_sentences = [tokenize_sentence(sentence) for sentence in sentences]\n",
    "len(tokenized_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f39112b",
   "metadata": {},
   "source": [
    "##### Word2VEC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "86acdd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "91c3ec35",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_model = Word2Vec(tokenized_sentences, vector_size=100, window=5, min_count=1, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2fc5753a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.47 s, sys: 44.5 ms, total: 5.52 s\n",
      "Wall time: 1.98 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3076549, 3252800)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "word2vec_model.train(tokenized_sentences, total_examples=len(tokenized_sentences), epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397021a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7d625ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vocabulary and word embeddings\n",
    "\n",
    "vocabulary = word2vec_model.wv.index_to_key\n",
    "word_embeddings = np.array([word2vec_model.wv[word] for word in vocabulary])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "47119d81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the vocabulary we have: 13628\n",
      "And Shape of the word embeddings is: (13628, 100)        \n",
      "Size of the each word vector is: 100\n"
     ]
    }
   ],
   "source": [
    "print(f'Size of the vocabulary we have: {len(vocabulary)}\\nAnd Shape of the word embeddings is: {word_embeddings.shape}\\\n",
    "        \\nSize of the each word vector is: {word_embeddings.shape[1]}'\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363eca01",
   "metadata": {},
   "source": [
    "###### Separating Train and Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d00be9ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_val is of length: 2000\n"
     ]
    }
   ],
   "source": [
    "X_train_val = tokenized_sentences[:2000]\n",
    "print(f'X_train_val is of length: {len(X_train_val)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f003cc1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train_val is of length: 2000\n"
     ]
    }
   ],
   "source": [
    "y_train_val = list(y_train_raw) \n",
    "y_train_val = torch.tensor(y_train_val)\n",
    "print(f'y_train_val is of length: {len(y_train_val)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ebd985e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test is of length: 500\n",
      "y_test is of length: 500\n"
     ]
    }
   ],
   "source": [
    "X_test = tokenized_sentences[2000:]\n",
    "y_test = y_test_raw\n",
    "\n",
    "print(f'X_test is of length: {len(X_test)}\\ny_test is of length: {len(y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5ac264",
   "metadata": {},
   "source": [
    "###### X will be converted later to numeric_indices by the word2vec.wv in the training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "41e86276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test sets\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bdbaed51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lengh of X_train is 1600\n",
      "Lengh of y_train is 1600 \n",
      "\n",
      "Lengh of X_train is 400\n",
      "Lengh of y_test is 400\n"
     ]
    }
   ],
   "source": [
    "print(f'Lengh of X_train is {len(X_train)}')\n",
    "print(f'Lengh of y_train is {len(y_train)} \\n')\n",
    "print(f'Lengh of X_train is {len(X_val)}')\n",
    "print(f'Lengh of y_test is {len(y_val)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31bc3234",
   "metadata": {},
   "source": [
    "#### Dataset and Dataloader Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9a7dfc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, data, labels, vocab):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.vocab = vocab\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        news = self.data[idx]\n",
    "        tokens = [self.vocab.index(word) for word in news]\n",
    "        return torch.tensor(tokens), torch.tensor(self.labels[idx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "14c50eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequences(batch):\n",
    "    \n",
    "    batch_size = len(batch)\n",
    "    max_len = max([len(seq) for seq, _ in batch])\n",
    "    padded_seqs = torch.zeros(batch_size, max_len, dtype=torch.long)\n",
    "    labels = torch.zeros(batch_size, dtype=torch.long)\n",
    "    for i, (seq, label) in enumerate(batch):\n",
    "        padded_seqs[i, :len(seq)] = seq\n",
    "        labels[i] = label\n",
    "    return padded_seqs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e4d05469",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = NewsDataset(X_train, y_train, vocabulary)\n",
    "train_loader = DataLoader(train_dataset, batch_size = 16, shuffle=True, collate_fn = pad_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6a45f6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = NewsDataset(X_val, y_val, vocabulary)\n",
    "val_loader = DataLoader(val_dataset, batch_size = 16, shuffle=True, collate_fn = pad_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3f3eaf2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = NewsDataset(X_test, y_test, vocabulary)\n",
    "test_loader = DataLoader(test_dataset, batch_size = 16, shuffle=True, collate_fn = pad_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "058e441a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_fn(y_true, y_pred):\n",
    "    \n",
    "    correct = torch.eq(y_true, y_pred).sum().item()\n",
    "    accuracy = ( correct/len(y_pred) ) * 100\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13859120",
   "metadata": {},
   "source": [
    "#### Define the Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010a72e9",
   "metadata": {},
   "source": [
    "Obsv: Average pooling increasing the accuracy from 45% to 81 % almost double. Sowe are using average pooling here on the output of the RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "45d8ac29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the vanilla RNN model with custom embedding layer\n",
    "\n",
    "class vanillaBiRNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, word_vector_size, hidden_size, output_size):\n",
    "        super(vanillaBiRNN, self).__init__()\n",
    "\n",
    "        self.embedding_layer = nn.Embedding.from_pretrained(torch.FloatTensor(word_embeddings), freeze = True)\n",
    "        self.rnn = nn.RNN(word_vector_size, hidden_size, batch_first = True, bidirectional = True)\n",
    "        self.fc = nn.Linear(hidden_size * 2, output_size)\n",
    "        self.softmax = nn.Softmax(dim = 1)\n",
    "\n",
    "    # There are 2*hidden_units in the linear layee bcz of the bidirectional nature of the RNN\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        embedded = self.embedding_layer(x)\n",
    "        output, _ = self.rnn(embedded)\n",
    "        \n",
    "        # Average pooling along the sequence dimension\n",
    "        avg_pooled = torch.mean(output, dim=1)  # Compute mean across the sequence dimension (dimension 1)\n",
    "        output = self.fc(avg_pooled)  \n",
    "        \n",
    "        softMaxedOutput = self.softmax(output)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "195f2db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of tokens we have\n",
    "vocab_size = len(word2vec_model.wv)\n",
    "\n",
    "# Size of the embedding vector that will be created by the embedding layer\n",
    "word_vector_size = 100\n",
    "\n",
    "# no. of nodes in the RNN Layer\n",
    "hidden_size = 200\n",
    "\n",
    "# Number of classes\n",
    "output_size = 4  \n",
    "\n",
    "# Number of epochs\n",
    "num_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "444597e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b8ddf611",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "vanillaBiRNN(\n",
       "  (embedding_layer): Embedding(13628, 100)\n",
       "  (rnn): RNN(100, 200, batch_first=True, bidirectional=True)\n",
       "  (fc): Linear(in_features=400, out_features=4, bias=True)\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biRNN = vanillaBiRNN(word_vector_size, hidden_size, output_size).to(device)\n",
    "biRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a2234f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function and optimizer\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(biRNN.parameters(), lr = 0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8e8b2b",
   "metadata": {},
   "source": [
    "Adam, 0.02, 28.50, epochs = 60\n",
    "\n",
    "Adam, 0.002, 35.50, epochs = 60\n",
    "\n",
    "Adam, 0.005, 30.25, epochs = 60\n",
    "\n",
    "Adam, 0.0005, 44.75, epochs = 60\n",
    "\n",
    "AdamW, 0.0005, 45.00, epochs = 60\n",
    "\n",
    "AdamW, 0.00005, 47.00, epochs = 60\n",
    "\n",
    "AdamW, 0.00005, 44.75, epochs = 100\n",
    "\n",
    "AdamW, 0.00005, 66.25, epochs = 25\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19951f0f",
   "metadata": {},
   "source": [
    "##### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7d01ed8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "373779531a9d4ffc8f62f235346a4e3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1 | Train loss: 1.1267 | Val loss: 0.8088 | Val accuracy: 71.7500\n",
      "Model State Dict Saved\n",
      "\n",
      "Epoch:2 | Train loss: 0.6898 | Val loss: 0.6339 | Val accuracy: 79.0000\n",
      "Model State Dict Saved\n",
      "\n",
      "Epoch:3 | Train loss: 0.5999 | Val loss: 0.5879 | Val accuracy: 78.2500\n",
      "Epoch:4 | Train loss: 0.5647 | Val loss: 0.6025 | Val accuracy: 79.0000\n",
      "Epoch:5 | Train loss: 0.5391 | Val loss: 0.5838 | Val accuracy: 78.7500\n",
      "Epoch:6 | Train loss: 0.5344 | Val loss: 0.5835 | Val accuracy: 80.5000\n",
      "Model State Dict Saved\n",
      "\n",
      "Epoch:7 | Train loss: 0.5186 | Val loss: 0.5240 | Val accuracy: 80.7500\n",
      "Model State Dict Saved\n",
      "\n",
      "Epoch:8 | Train loss: 0.5033 | Val loss: 0.5084 | Val accuracy: 82.5000\n",
      "Model State Dict Saved\n",
      "\n",
      "Epoch:9 | Train loss: 0.5004 | Val loss: 0.5305 | Val accuracy: 80.2500\n",
      "Epoch:10 | Train loss: 0.5023 | Val loss: 0.5201 | Val accuracy: 81.5000\n",
      "Epoch:11 | Train loss: 0.4907 | Val loss: 0.5100 | Val accuracy: 80.7500\n",
      "Epoch:12 | Train loss: 0.4794 | Val loss: 0.5261 | Val accuracy: 81.0000\n",
      "Epoch:13 | Train loss: 0.4909 | Val loss: 0.5071 | Val accuracy: 82.5000\n",
      "Epoch:14 | Train loss: 0.4760 | Val loss: 0.5118 | Val accuracy: 81.2500\n",
      "Epoch:15 | Train loss: 0.4629 | Val loss: 0.5019 | Val accuracy: 81.5000\n",
      "Epoch:16 | Train loss: 0.4535 | Val loss: 0.5322 | Val accuracy: 81.7500\n",
      "Epoch:17 | Train loss: 0.4772 | Val loss: 0.5147 | Val accuracy: 80.2500\n",
      "Epoch:18 | Train loss: 0.4534 | Val loss: 0.4893 | Val accuracy: 81.0000\n",
      "Epoch:19 | Train loss: 0.4502 | Val loss: 0.5032 | Val accuracy: 82.5000\n",
      "Epoch:20 | Train loss: 0.4471 | Val loss: 0.4802 | Val accuracy: 82.2500\n"
     ]
    }
   ],
   "source": [
    "performance_metrics = []\n",
    "best_val_accuracy = 0\n",
    "\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    \n",
    "    biRNN.train()\n",
    "    train_loss = 0\n",
    "    \n",
    "    for batch_idx, (X, y) in enumerate(train_loader):\n",
    "        \n",
    "        X, y = X.to(device), y.to(device)\n",
    "        \n",
    "        y_pred = biRNN(X)\n",
    "                \n",
    "        # calculate batch accumulative loss\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "    with torch.inference_mode():\n",
    "        \n",
    "        biRNN.eval()\n",
    "        val_loss, val_accuracy = 0,0\n",
    "        \n",
    "        for X_val, y_val in val_loader:\n",
    "            \n",
    "            X_val, y_val = X_val.to(device), y_val.to(device)\n",
    "            \n",
    "            y_val_pred = biRNN(X_val)\n",
    "            \n",
    "            loss = loss_fn(y_val_pred, y_val)\n",
    "            val_loss += loss\n",
    "            val_accuracy += accuracy_fn(y_val, y_val_pred.argmax(dim=1))\n",
    "        \n",
    "        # Calculate avg. loss & accuracy\n",
    "        \n",
    "        train_loss = train_loss / len(train_loader)\n",
    "        val_loss = val_loss / len(val_loader)\n",
    "        val_accuracy = val_accuracy / len(val_loader)\n",
    "        \n",
    "        print(f\"Epoch:{epoch+1} | Train loss: {train_loss:.4f} | Val loss: {val_loss:.4f} | Val accuracy: {val_accuracy:.4f}\")\n",
    "        performance_metrics.append(val_accuracy)\n",
    "\n",
    "        if val_accuracy > best_val_accuracy:\n",
    "            torch.save(biRNN.state_dict(), './best_biRNN_model.pth')\n",
    "            print('Model State Dict Saved\\n')\n",
    "            best_val_accuracy = val_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31839d4",
   "metadata": {},
   "source": [
    "### Evaluation on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f934e9d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67de346201e74c4f86eafdadbf24e27d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.5295 | Test accuracy: 81.45\n"
     ]
    }
   ],
   "source": [
    "# Load the latest Best checkpoint saved above.\n",
    "y_predicted_list, y_test_true = [],[]\n",
    "\n",
    "biRNN.load_state_dict(torch.load('./best_biRNN_model.pth'))\n",
    "\n",
    "with torch.inference_mode():\n",
    "    biRNN.eval()\n",
    "    test_loss, test_accuracy = 0,0\n",
    "\n",
    "    for X_test, y_test in tqdm(test_loader):\n",
    "\n",
    "        X_test, y_test = X_test.to(device), y_test.to(device)\n",
    "\n",
    "        y_test_pred = biRNN(X_test)\n",
    "        \n",
    "        y_predicted_list.append(y_test_pred.argmax(dim = 1))\n",
    "        y_test_true.append(y_test)\n",
    "\n",
    "        loss = loss_fn(y_test_pred, y_test)\n",
    "        test_loss += loss\n",
    "        test_accuracy += accuracy_fn(y_test, y_test_pred.argmax(dim=1))\n",
    "\n",
    "    # Calculate avg. loss & accuracy\n",
    "    test_loss = test_loss/len(test_loader)\n",
    "    test_accuracy = test_accuracy/len(test_loader)\n",
    "\n",
    "    print(f\"Test loss: {test_loss:.4f} | Test accuracy: {test_accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f505639b",
   "metadata": {},
   "source": [
    "#### Test Accuracy of the Bi-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ae50fcd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy for the Bi-RNN model is: 81.45 %\n"
     ]
    }
   ],
   "source": [
    "print(f'Test Accuracy for the Bi-RNN model is: {test_accuracy:.2f} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "79df63c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the list of tensors to a single list of elements\n",
    "\n",
    "y_predicted_list = [item for tensor in y_predicted_list for item in tensor.tolist()]\n",
    "y_test_true = [item for tensor in y_test_true for item in tensor.tolist()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725451c5",
   "metadata": {},
   "source": [
    "#### F-1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4183035c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score for the model is: 0.8154\n"
     ]
    }
   ],
   "source": [
    "f1 = f1_score(np.array(y_test_true), np.array(y_predicted_list), average='weighted')\n",
    "print(f'F1 Score for the model is: {f1:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac14980f",
   "metadata": {},
   "source": [
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b5b4c82c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate confusion matrix\n",
    "cm = confusion_matrix(y_test_true, y_predicted_list)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(7, 4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='crest', cbar=False)\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9fabf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eaa1db3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27996a92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
